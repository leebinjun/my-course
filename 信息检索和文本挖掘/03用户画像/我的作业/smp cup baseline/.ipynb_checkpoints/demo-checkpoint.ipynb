{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "该程序可以对语料进行简单处理，使用TFIDF特征及逻辑回归算法进行三个任务的预测\n",
    "将输出文件temp.csv，将该文件提交到评测系统中，可得到baseline的结果\n",
    "该程序运行需要4个文件\n",
    "train/train_status.txt\n",
    "train/train_labels.txt\n",
    "valid/valid_status.txt\n",
    "valid/valid_nolabel.txt\n",
    "'''\n",
    "provsString='''\n",
    "    东北,辽宁,吉林,黑龙江\n",
    "    华北,河北,山西,内蒙古,北京,天津\n",
    "    华东,山东,江苏,安徽,浙江,台湾,福建,江西,上海\n",
    "    华中,河南,湖北,湖南\n",
    "    华南,广东,广西,海南,香港,澳门\n",
    "    西南,云南,重庆,贵州,四川,西藏\n",
    "    西北,新疆,陕西,宁夏,青海,甘肃\n",
    "    境外,其他,海外\n",
    "    None,None\n",
    "    '''\n",
    "provs={}\n",
    "for line in provsString.split('\\n'):\n",
    "    items=line.split(',')\n",
    "    for item in items[1:]:\n",
    "        provs[item]=items[0].strip()\n",
    "    \n",
    "def map_age(x):\n",
    "    x=int(x)\n",
    "    if x>=1990:\n",
    "        return '1990+'\n",
    "    elif x<1980:\n",
    "        return '1979-'\n",
    "    else:\n",
    "        return '1980-1989'\n",
    "    \n",
    "def map_location(x):\n",
    "    x=x.split(' ')[0]\n",
    "    return provs[x]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从文件中读取语料并整理，将同一个人发的微博连在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#读取训练集\n",
    "train_file=map(lambda x:x.split(',',maxsplit=5),\n",
    "               open('train/train_status.txt',encoding='utf8'))\n",
    "valid_labels=set(map(lambda x:x.strip(),open('valid/valid_nolabel.txt')))\n",
    "valid_file=filter(lambda x:x[0] in valid_labels,\n",
    "                  map(lambda x:x.split(',',maxsplit=5),\n",
    "                      open('valid/valid_status.txt',encoding='utf8')))\n",
    "\n",
    "df=pd.DataFrame(data=list(train_file)+list(valid_file),\n",
    "                columns='id,review,forward,source,time,content'.split(','),)\n",
    "\n",
    "#读取训练集标注\n",
    "labels=pd.read_csv('train/train_labels.txt',sep='\\|\\|',encoding='utf8',engine='python',\n",
    "                   names='id,gender,age,location'.split(','))\n",
    "\n",
    "labels.age=labels.age.apply(map_age)\n",
    "labels.location=labels.location.apply(map_location)\n",
    "\n",
    "#按id进行合并微博内容\n",
    "X=pd.DataFrame(df.groupby(by='id',sort=False).content.sum()).reset_index()\n",
    "X.id=X.id.astype(int)\n",
    "\n",
    "data=pd.merge(X,labels,on='id',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从文本中抽取TFIDF特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf=TfidfVectorizer(max_features=10000)\n",
    "f_tfidf=tfidf.fit_transform(data.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练逻辑回归分类器，并进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model.logistic import LogisticRegression as LR\n",
    "\n",
    "valid_data=data[3200:].reset_index()\n",
    "\n",
    "clf=LR()\n",
    "clf.fit(f_tfidf[:3200],data.gender[:3200])\n",
    "valid_data.gender=clf.predict(f_tfidf[3200:])\n",
    "\n",
    "clf=LR()\n",
    "clf.fit(f_tfidf[:3200],data.age[:3200])\n",
    "valid_data.age=clf.predict(f_tfidf[3200:])\n",
    "\n",
    "clf=LR()\n",
    "clf.fit(f_tfidf[:3200],data.location[:3200])\n",
    "valid_data.location=clf.predict(f_tfidf[3200:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出到temp.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data.loc[:,['id','age','gender','location']].to_csv('temp.csv',index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7981db30c93e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m clf=XGBClassifier(learning_rate =0.01, n_estimators=5000, max_depth=4, min_child_weight=2,\n\u001b[0;32m      7\u001b[0m                   gamma=0.1, subsample=0.5, colsample_bytree=0.6)\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_tfidf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgender\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgender\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_tfidf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mJ:\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[0;32m    505\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mJ:\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mJ:\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mJ:\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    894\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m--> 896\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m    897\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "\n",
    "valid_data=data[3200:].reset_index()\n",
    "\n",
    "clf=XGBClassifier(learning_rate =0.2, n_estimators=500, max_depth=4, min_child_weight=2,\n",
    "                  gamma=0.1, subsample=0.5, colsample_bytree=0.6)\n",
    "clf.fit(f_tfidf[:3200],data.gender[:3200])\n",
    "valid_data.gender=clf.predict(f_tfidf[3200:])\n",
    "\n",
    "clf=XGBClassifier(learning_rate =0.2, n_estimators=500, max_depth=4, min_child_weight=2,\n",
    "                  gamma=0.1, subsample=0.5, colsample_bytree=0.6)\n",
    "clf.fit(f_tfidf[:3200],data.age[:3200])\n",
    "valid_data.age=clf.predict(f_tfidf[3200:])\n",
    "\n",
    "clf=XGBClassifier(learning_rate =0.2, n_estimators=500, max_depth=4, min_child_weight=2,\n",
    "                  gamma=0.1, subsample=0.5, colsample_bytree=0.6)\n",
    "clf.fit(f_tfidf[:3200],data.location[:3200])\n",
    "valid_data.location=clf.predict(f_tfidf[3200:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
